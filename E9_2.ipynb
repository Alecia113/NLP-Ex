{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E9.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJ0/rx2pCbz+0CmxNHsNIl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alecia113/NLP-Ex/blob/main/E9_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxMlHBOIUFza"
      },
      "source": [
        "新\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSfmsswBUFR9"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate\n",
        "drive = None\n",
        "def authenticate():\n",
        "    global drive\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "#Download files\n",
        "def downloadFiles(fileIds):\n",
        "    authenticate()\n",
        "    for fileId in fileIds:    \n",
        "        downloaded = drive.CreateFile({\"id\": fileId[1]})\n",
        "        downloaded.GetContentFile(fileId[0])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egNMhYx7qFs7"
      },
      "source": [
        "#Download file if not existing\n",
        "try:\n",
        "  _ = open(\"train.txt\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"train.txt\", \"1UmNHdUZxjfcuIzCcAKuBvfBXdSWFv47i\"]])\n",
        "\n",
        "try:\n",
        "  _ = open(\"validation.txt\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"validation.txt\", \"11bZIh5V9m2nZJ5s5xQ_gxHEHkAEhV8eQ\"]])\n",
        "\n",
        "try:\n",
        "  _ = open(\"test.txt\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"test.txt\", \"1V-LQuJWT62aCytYuhZuaxvICsqiF1rdK\"]])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsURxyItqNCT"
      },
      "source": [
        "def read_data(file_name, n_sample):\n",
        "    f = open(file_name)\n",
        "    documents = f.readlines()\n",
        "\n",
        "    input_data = []\n",
        "    target_data = []\n",
        "\n",
        "    temp1 = []\n",
        "    temp2 = []\n",
        "    for i in documents:\n",
        "        if i == '\\n':\n",
        "            input_data.append(temp1)\n",
        "            target_data.append(temp2)\n",
        "            temp1 = []\n",
        "            temp2 = []\n",
        "        else:\n",
        "            temp1.append(i.replace('\\n','').split(' ')[0].lower())\n",
        "            temp2.append(i.replace('\\n','').split(' ')[3])\n",
        "    return input_data[:n_sample], target_data[:n_sample]\n",
        "\n",
        "train_data, target_y_train = read_data(\"train.txt\",400)\n",
        "validation_data, target_y_validation = read_data(\"validation.txt\",50)\n",
        "test_data, target_y_test = read_data(\"test.txt\",50)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GASvK913tAmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7d78e5-071a-4a51-bb18-5621879c0096"
      },
      "source": [
        "print(len(train_data))\n",
        "print(train_data[1])\n",
        "print(target_y_train[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n",
            "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
            "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MWAK0NV3INF"
      },
      "source": [
        "word_to_ix = {}\n",
        "for sentence in train_data+validation_data+test_data:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in target_y_train+target_y_validation:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0b36A3pL8Z7",
        "outputId": "63e4963a-a1df-4cdf-bfee-4e857f053ca8"
      },
      "source": [
        "tag_to_ix"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<START>': 0,\n",
              " '<STOP>': 1,\n",
              " 'B-LOC': 7,\n",
              " 'B-MISC': 8,\n",
              " 'I-LOC': 6,\n",
              " 'I-MISC': 4,\n",
              " 'I-ORG': 3,\n",
              " 'I-PER': 5,\n",
              " 'O': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oz6KVyjsxM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cda944-ee65-42d9-9103-72ce29476eb2"
      },
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "\n",
        "word_emb_model = api.load(\"glove-twitter-25\") \n",
        "\n",
        "EMBEDDING_DIM = 25\n",
        "\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2351, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRs6mouFwEx4"
      },
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_data,word_to_ix)\n",
        "train_output_index = to_index(target_y_train,tag_to_ix)\n",
        "val_input_index = to_index(validation_data,word_to_ix)\n",
        "val_output_index = to_index(target_y_validation,tag_to_ix)\n",
        "test_input_index = to_index(test_data,word_to_ix)\n",
        "test_output_index = to_index(target_y_test,tag_to_ix)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKgXoICaMq4Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5AgRWakkfmT"
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glMscETqUeYX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuzZ_et6FD7"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 50\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lTtSPre6pPb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr8zlEYSUhAI",
        "outputId": "72146d06-0e36-402f-eb9f-18b0c76593f7"
      },
      "source": [
        "#print(model(torch.tensor(train_input_index[10])))  \n",
        "#print(model(torch.tensor(train_input_index[13]))) #(tensor(17.8348, grad_fn=<SelectBackward>), [8, 8, 8, 8, 8, 8, 8, 8, 8])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor(17.8348, grad_fn=<SelectBackward>), [8, 8, 8, 8, 8, 8, 8, 8, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g23sB-BRn44t",
        "outputId": "f027bfa9-0f90-455e-b7f8-9b8fe9eeb02a"
      },
      "source": [
        "train_input_index[13]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[143, 119, 84, 53, 166, 98, 38, 92, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obwjquN9UaT9"
      },
      "source": [
        "做\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl4wvD1hV61F"
      },
      "source": [
        "# #给的\n",
        "# # Check predictions before training\n",
        "# with torch.no_grad():\n",
        "#     precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "#     precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
        "#     print(model(precheck_sent))\n",
        "\n",
        " \n",
        "# # Check predictions after training\n",
        "# with torch.no_grad():\n",
        "#     precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "#     print(model(precheck_sent))\n",
        "#     #(tensor(2.6907), [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
        "# # We got it\n",
        "# #https://blog.csdn.net/kyle1314608/article/details/100589398?ops_request_misc=&request_id=&biz_id=102&utm_term=python%20Bi-LSTM%20with%20CRF&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-8-.first_rank_v2_pc_rank_v29&spm=1018.2226.3001.4187"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9wFjHfCDpxT"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJmu0oSsjLBm"
      },
      "source": [
        "import numpy as np\n",
        "def cal_acc(model, input_index, output_index): #完整的话\n",
        "  ground_truth = []\n",
        "  for i in range(len(train_output_index)): #i 0-400\n",
        "    for n in range(len(train_output_index[i])):\n",
        "      ground_truth.append(train_output_index[i][n])\n",
        "  \n",
        "  predicted = []\n",
        "  for sen in range(len(train_input_index)):\n",
        "    score, tag_seq = model.forward(torch.tensor(train_input_index[sen]))\n",
        "    for word in range(len(tag_seq)):\n",
        "      predicted.append(tag_seq[word])\n",
        "          \n",
        "  # for sen in range(len(input_index)):\n",
        "  #   score, tag_seq = model.forward(torch.tensor(input_index[sen]))\n",
        "  #    #分数和最佳路径 tag_seq tensor(6.2484, grad_fn=<SelectBackward>)[8, 3, 2, 6] #tag_seq一句话的标签。\n",
        "\n",
        "  accuracy = sum(true == pre for true,pre in zip(ground_truth,predicted))/len(ground_truth)\n",
        "  return predicted, ground_truth, accuracy"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFOkaZ6nUhY8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0CMFVSwlLru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "db19bf47-4c5e-4b08-a080-942d8ae4d772"
      },
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(20):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "#print(\"Epoch:%d, Training loss: %.2f\" %(epoch+1, train_loss))\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "    #验证\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-918f4081e957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtags_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_output_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIh-mWrvi6Pw"
      },
      "source": [
        "# Call the cal_acc functions you implemented as required\n",
        "y_pred, y_true, _ = cal_acc(model,test_input_index,test_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAnJVsyPq5kR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa179577-6359-4a7b-ab36-e8f8973703d1"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_decode,y_pred_decode,digits=4))\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC     0.0000    0.0000    0.0000         1\n",
            "      B-MISC     0.0000    0.0000    0.0000         1\n",
            "       I-LOC     0.9626    0.9930    0.9775       285\n",
            "      I-MISC     0.9775    0.9667    0.9721       180\n",
            "       I-ORG     0.9856    0.8952    0.9382       229\n",
            "       I-PER     0.9823    0.9929    0.9876       280\n",
            "           O     0.9963    0.9990    0.9977      4907\n",
            "\n",
            "    accuracy                         0.9930      5883\n",
            "   macro avg     0.7006    0.6924    0.6962      5883\n",
            "weighted avg     0.9927    0.9930    0.9928      5883\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tomtqMXWUjrS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}